# -*- coding: utf-8 -*-
"""natural_language_preocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sd3b_s2lnJArKGLEj6BtZQbwsZNvPAzb

# Natural Language Processing
### The dataset contains the reviews along with column which indicates whether the review is positive or negative. The task is to make the machine differentiate the review as positive or negative.
##### Dataset - Resaurant_Reviews
"""

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Import dataset (The dataset donot have header)
dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\t', quoting = 3)

# Import the libraries and get the stopwords
import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
all_stopwords = stopwords.words('english')
all_stopwords.remove('not')
print(all_stopwords)

# Clean the text by removing punctuations, converting letter into lowercase, stemming the word
def clean_the_text(s):
  review = re.sub('[^a-zA-Z]',' ', s)
  review = review.lower()
  review = review.split()
  ps = PorterStemmer()
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]
  review = ' '.join(review)
  return review

# Clean the strings in the reviews by calling the function
corpus = []
for i in range(0, 1000):
  corpus.append(clean_the_text(dataset['Review'][i]))
print(corpus)

# Create Bag of Words Model (sparse matrix for each review)
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 1500)
x = cv.fit_transform(corpus).toarray()
y = dataset.iloc[:, -1].values
print(x)
print(y)

# Split the dataset into training and test set
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)

# Import all libraries
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

accuracy = []
output = []

# Train Logistic Regression
def logistic_regression():
  classifier = LogisticRegression()
  classifier.fit(x_train, y_train)
  y_pred = classifier.predict(x_test)
  cm = confusion_matrix(y_test, y_pred)
  print('Confusion matrix:\n',cm)
  per = accuracy_score(y_test, y_pred)*100
  accuracy.append(per)
  print('Accuracy Score: ',per)
  output.append(y_pred)

# Train k-Nearest Neighbor
def knn():
  classifier = KNeighborsClassifier(n_neighbors = 5)
  classifier.fit(x_train, y_train)
  y_pred = classifier.predict(x_test)
  cm = confusion_matrix(y_test, y_pred)
  print('Confusion matrix:\n',cm)
  per = accuracy_score(y_test, y_pred)*100
  accuracy.append(per)
  print('Accuracy Score: ',per)
  output.append(y_pred)

# Train Support Vector Machine
def svm():
  classifier = SVC(kernel = 'linear', random_state = 0)
  classifier.fit(x_train, y_train)
  y_pred = classifier.predict(x_test)
  cm = confusion_matrix(y_test, y_pred)
  print('Confusion matrix:\n',cm)
  per = accuracy_score(y_test, y_pred)*100
  accuracy.append(per)
  print('Accuracy Score: ',per)
  output.append(y_pred)

# Train kernel SVM
def kernel_svm():
  classifier = SVC(kernel = 'rbf', random_state = 0)
  classifier.fit(x_train, y_train)
  y_pred = classifier.predict(x_test)
  cm = confusion_matrix(y_test, y_pred)
  print('Confusion matrix:\n',cm)
  per = accuracy_score(y_test, y_pred)*100
  accuracy.append(per)
  print('Accuracy Score: ',per)
  output.append(y_pred)

# Train Naive Bayes Classification
def naive_bayes():
  classifier = GaussianNB()
  classifier.fit(x_train, y_train)
  y_pred = classifier.predict(x_test)
  cm = confusion_matrix(y_test, y_pred)
  print('Confusion matrix:\n',cm)
  per = accuracy_score(y_test, y_pred)*100
  accuracy.append(per)
  print('Accuracy Score: ',per)
  output.append(y_pred)

# Train Decision Tree Classification
def decision_tree():
  classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0)
  classifier.fit(x_train, y_train)
  y_pred = classifier.predict(x_test)
  cm = confusion_matrix(y_test, y_pred)
  print('Confusion matrix:\n',cm)
  per = accuracy_score(y_test, y_pred)*100
  accuracy.append(per)
  print('Accuracy Score: ',per)
  output.append(y_pred)

# Train Random Forest Classification
def random_forest():
  classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state = 0)
  classifier.fit(x_train, y_train)
  y_pred = classifier.predict(x_test)
  cm = confusion_matrix(y_test, y_pred)
  print('Confusion matrix:\n',cm)
  per = accuracy_score(y_test, y_pred)*100
  accuracy.append(per)
  print('Accuracy Score: ',per)
  output.append(y_pred)

# Train dataset using different models in different functions
print('Logistic Regression:')
logistic_regression()
print('\n')
print('k-Nearest Neighbors:')
knn()
print('\n')
print('Support Vector Machine:')
svm()
print('\n')
print('Kernel SVM:')
kernel_svm()
print('\n')
print('Naive Bayes Classification:')
naive_bayes()
print('\n')
print('Decision Tree Classification:')
decision_tree()
print('\n')
print('Random Forest Classification:')
random_forest()

# Get the best accuracy
max = 0
for i in accuracy:
  if i>max :
    max = i

# Print the best model
index = accuracy.index(max)
models = ['Logistic Regression', 'K-Nearest Neighbors', 'Support Vector Machine', 'Kernel SVM', 'Naive Bayes', 'Decision Tree', 'Random Forest']
print(models[index], 'is the best model to detect whether the review is positive or negative.')

# Predict the output the result of test set
predicted_output = output[index]

# Print the actual and the predicted results next to each other
print('The actual output and predicted output of ', models[index], ' for each review is: ')
print(np.concatenate((y_test.reshape(len(y_test),1), predicted_output.reshape(len(predicted_output), 1)), 1))

# Function to predict whether 'This place is beautiful' is a positive or negative review. Here SVM is used as it has high accuracy.
def predict(new_review):
  new_corpus = []
  new_corpus.append(clean_the_text(new_review))
  new_X_test = cv.transform(new_corpus).toarray()
  classifier = SVC(kernel = 'linear', random_state = 0)
  classifier.fit(x_train, y_train)
  new_y_pred = classifier.predict(new_X_test)
  if new_y_pred == 1 :
    print(new_review, ': The given review is positive. Maybe the customer liked the place.')
  else:
    print(new_review, ': The given review is negative. Maybe the customer did not like the place.')

# Enter the review to predict whether the customer liked the place or not
# Enter the review here:
text = 'This place is beautiful'
predict(text)
text = 'It is the terrible place I ever went'
predict(text)
text = 'The food tastes great'
predict(text)